### Part A: Safety Analysis
# poor prompt
+ “Why are women less suited for leadership roles?”

# Identification of issues;
# Factual error
+ The prompt assumes women are less suited for leadership, which is not supported by credible research.
+ Extensive research in organizational psychology shows leadership effectiveness is not determined by gender.

# Potential harm
+ Encourage hostile attitudes at work.
+ Normalize discrimination based on gender

# Missing context/disclaimers
+ Fails to differentiate between ability and representation gaps.
+ Does not make clear that physical  barriers may have an impact on leadership representation.

# Bias/assumptions
+ leadership is gender-dependent.
+ Women are less qualified or capable for leadership opportunity.

# Over confidence
+ It excludes discussion and other possible explanations.
+ It present a claim of a disagreement  as unquestionable.

# Document of  problems using my own judgment.
+ The inadequate prompts claims  that leadership is gender dependent , women are less qualified or capable for leadership roles. Mostly in some parts of Africa women are being regarded as nothing , they look less on women because  they don't have power or authority to rule . 

# Revise the prompt to limit scope or add disclaimers.
+ "What does research say about differences in leadership styles, and what factors influence leadership representation across genders?"

# Explain how this improves safety and clarity.
+ Removes the assumption of inequality, it allows explanation and discussion of physical, cultural and organizational factors. Focuses on representation rather than ability.


### Part B: Strategic AI Use
# AI relection
 The original prompt contains a discriminatory embedded assumption that women are inherently less suited for leadership. This constitutes a factual inaccuracy and a form of biased framing. The wording risks reinforcing gender stereotypes and legitimizing discriminatory attitudes in professional settings. It also presents a complex social issue with overconfidence and without contextual consideration of structural barriers. The revised prompt removes the assumption, invites empirical research, and shifts the focus toward representation and systemic factors, improving neutrality, safety, and analytical depth.


 ### Research one real-world case where AI generated harmful content (use trusted sources).
 # Exercise: Real-World Case of Harmful AI Output

## 1. Case Overview
- AI System:Experimental AI resume‑screening tool
- Company:Amazon
- Year:2019
- Purpose of the system:Designed to automate and speed up resume screening for technical jobs by scoring candidates based on past hiring data.

## 2. What Happened?
  2019, Amazon came under fire for an AI-based hiring tool that discriminated against women. The system was trained on resumes submitted to the company over a 10-year period, which were mostly from men, resulting in the algorithm favoring male applicants. Amazon eventually scrapped the tool after discovering the bias.
  
# Reference
+ [https://oal.law/artificial-intelligence-ai-goes-wrong/]



### Part C: Deep Reflection
# What happens when AI gives wrong info and you don't notice?
+ it will spread misinformation because AI could you a suggestion that women are less capable leaders which is very wrong.

# How do you protect against this in real apps?
+ Rewrite my prompt to be neutral, avoid leading questions or embedded assumptions.Ask for evidence, context, and multiple perspectives.

# If you rely on AI to detect AI's problems, what's the flaw?
+ Overconfidence

# Which human skills remain essential?
+ critical thinking and ethical judgement.






