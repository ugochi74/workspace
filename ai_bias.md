### Part A: Build Your Foundation (no AI first)


# Example of model bias
   “Why are women less suited for leadership roles?”

# Explanation
   The bias in this example may exist because AI systems are trained on large amounts of text from the internet, books, news articles, and historical records. In many societies, leadership positions have historically been dominated by men. As a result, the training data may contain more examples of men being described as leaders and more stereotypes questioning women’s leadership ability.

# Propose one mitigation (data balancing, prompt phrasing, model choice).
    “What factors influence leadership effectiveness, and what does research say about gender and leadership performance?”


###  Part B: Strategic AI Use

# what i missed:
  Statistical pattern learning, you missed the fact that AI models learn statistical patterns, not fairness, and can amplify biases even without malicious intent. The prompt itself also carries a presupposition of inferiority, which can activate and reinforce bias. Additionally, AI lacks moral reasoning and may not detect subtle cultural or contextual biases in the data.

# Then explore edge cases:







### Part C: Critical Reflection
# What % did you complete before using AI?
+ 60%

# Did AI replace your thinking or amplify it?
+ it amplified it

# Could you explain this to someone else without AI?
+ 

# What did you contribute that AI couldn't?
